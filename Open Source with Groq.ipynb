{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groq\n",
    "\n",
    "[Groq](https://groq.com/) is a cloud based platform serving a number of popular open weight models at high inference speeds. Models include Meta's Llama 3, Mistral AI's Mixtral, and Google's Gemma.\n",
    "\n",
    "Although Groq's API is aligned well with OpenAI's, which is the native API used by AutoGen, this library provides the ability to set specific parameters as well as track API costs.\n",
    "\n",
    "You will need a Groq account and create an API key. [See their website for further details](https://groq.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models have become increasingly important in recent years due to their ability to process and generate human-like language quickly and efficiently. Here are some reasons why fast language models are important:\n",
      "\n",
      "1. **Real-time Processing**: Fast language models can process and respond to user input in real-time, making them ideal for applications that require immediate responses, such as chatbots, virtual assistants, and language translation systems.\n",
      "2. **Scalability**: Fast language models can handle large volumes of data and scale to meet the demands of big data applications, such as text classification, sentiment analysis, and language modeling.\n",
      "3. **Improved User Experience**: By providing fast and accurate responses, fast language models can improve the user experience in applications such as search engines, customer service chatbots, and language translation systems.\n",
      "4. **Enhanced Decision-Making**: Fast language models can quickly analyze large amounts of text data, enabling businesses to make data-driven decisions faster and more accurately.\n",
      "5. **Advancements in NLP**: Fast language models have driven advancements in Natural Language Processing (NLP) research, enabling the development of more sophisticated NLP applications, such as language translation, text summarization, and question answering.\n",
      "6. **Automation**: Fast language models can automate many tasks that previously required human intervention, such as data entry, document processing, and content generation.\n",
      "7. **Cost Savings**: By automating tasks and improving efficiency, fast language models can help reduce costs and increase productivity in various industries.\n",
      "8. **Increased Accessibility**: Fast language models can provide language translation and interpretation services to people who may not speak the same language, increasing accessibility and bridging language gaps.\n",
      "9. **Enhanced Security**: Fast language models can be used to detect and prevent cyber threats, such as phishing and spam, by quickly analyzing and processing large amounts of text data.\n",
      "10. **New Applications**: Fast language models have enabled the development of new applications, such as language-based games, interactive storytelling, and creative writing tools.\n",
      "\n",
      "Some examples of fast language models include:\n",
      "\n",
      "* BERT (Bidirectional Encoder Representations from Transformers)\n",
      "* RoBERTa (Robustly Optimized BERT Pretraining Approach)\n",
      "* DistilBERT (Distilled BERT)\n",
      "* T5 (Text-to-Text Transformer)\n",
      "* XLNet (eXtra Large Language Model)\n",
      "\n",
      "These models have achieved state-of-the-art results in various NLP tasks and have been widely adopted in industry and academia.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key='')\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    #\n",
    "    # Required parameters\n",
    "    #\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant.\"\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    # The language model which will generate the completion.\n",
    "    model=\"llama3-8b-8192\",\n",
    "\n",
    "    #\n",
    "    # Optional parameters\n",
    "    #\n",
    "\n",
    "    # Controls randomness: lowering results in less random completions.\n",
    "    # As the temperature approaches zero, the model will become deterministic\n",
    "    # and repetitive.\n",
    "    temperature=0.5,\n",
    "\n",
    "    # The maximum number of tokens to generate. Requests can use up to\n",
    "    # 32,768 tokens shared between prompt and completion.\n",
    "    max_tokens=1024,\n",
    "\n",
    "    # Controls diversity via nucleus sampling: 0.5 means half of all\n",
    "    # likelihood-weighted options are considered.\n",
    "    top_p=1,\n",
    "\n",
    "    # A stop sequence is a predefined or user-specified text string that\n",
    "    # signals an AI to stop generating content, ensuring its responses\n",
    "    # remain focused and concise. Examples include punctuation marks and\n",
    "    # markers like \"[end]\".\n",
    "    stop=None,\n",
    "\n",
    "    # If set, partial message deltas will be sent.\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "# Print the completion returned by the LLM.\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
