{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24b7857",
   "metadata": {},
   "source": [
    "# Workshop 11 : Fine-tune a Small Open-source Model with Your Custom Dataset\n",
    "In this workshop, you'll:\n",
    "- Load a text dataset (CSV format) for classification\n",
    "- Tokenize text using a Hugging Face tokenizer\n",
    "- Load a small Transformer model (e.g., DistilBERT)\n",
    "- Fine-tune the model on your data\n",
    "- Evaluate and make predictions\n",
    "\n",
    "This notebook works for both English and Thai (change model/dataset as needed).\n",
    "\n",
    "**Requirements:** Place `train.csv` and `val.csv` in the same directory with columns: `text`, `label`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221cfead",
   "metadata": {},
   "source": [
    "## Step 1: Install dependencies (if needed)\n",
    "You may need to restart your kernel after installing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55c559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch pandas scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6256a",
   "metadata": {},
   "source": [
    "## Step 2: Load Custom Dataset\n",
    "Assumes `train.csv` and `val.csv` with columns: `text`, `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2f67e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      text       label\n",
      "0    ร้านอาหารไหนอร่อยบ้าง  restaurant\n",
      "1            Good morning!    greeting\n",
      "2             ขอบคุณมากค่ะ   gratitude\n",
      "3                 Bye bye!     goodbye\n",
      "4   I really appreciate it   gratitude\n",
      "..                     ...         ...\n",
      "67       มีรถไฟฟ้าใกล้ๆไหม      travel\n",
      "68           สวัสดีตอนเย็น    greeting\n",
      "69         ห้องน้ำไม่สะอาด   complaint\n",
      "70         อาหารเย็นเกินไป   complaint\n",
      "71    My room is too noisy   complaint\n",
      "\n",
      "[72 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv')\n",
    "val_df = pd.read_csv('val.csv')\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6f20909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'complaint': 0, 'goodbye': 1, 'gratitude': 2, 'greeting': 3, 'joke': 4, 'restaurant': 5, 'travel': 6, 'weather': 7}\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "labels = sorted(train_df['label'].unique())\n",
    "label2id = {l: i for i, l in enumerate(labels)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "train_df['labels'] = train_df['label'].map(label2id)\n",
    "val_df['labels'] = val_df['label'].map(label2id)\n",
    "\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd6e993",
   "metadata": {},
   "source": [
    "## Step 3: Tokenization\n",
    "Pick a pre-trained model (`distilbert-base-uncased`, `airesearch/wangchanberta-base-att-spm-uncased` for Thai, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9bcaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# You can change to a Thai model, e.g. 'airesearch/wangchanberta-base-att-spm-uncased'\n",
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example['text'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad997a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebf6edf08ad4962b23044e50619b5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a8b1de489e4496b66f853f03cbcdb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[['text', 'labels']])\n",
    "val_ds = Dataset.from_pandas(val_df[['text', 'labels']])\n",
    "\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "cols = ['input_ids', 'attention_mask', 'labels']\n",
    "train_ds.set_format(type='torch', columns=cols)\n",
    "val_ds.set_format(type='torch', columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fe93471-4ae2-482d-bd4e-009697458e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9408654",
   "metadata": {},
   "source": [
    "## Step 4: Load Pre-trained Model for Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd2cbd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f0d74e-e4f9-43d0-bb47-1024675d233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/homebrew/anaconda3/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da710d7-1eed-4ca9-96c5-15fa235a0624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52.4\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c703ba",
   "metadata": {},
   "source": [
    "## Step 5: Set Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c3f1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    do_eval=True,  \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    logging_steps=20,\n",
    "    report_to='none',\n",
    "    load_best_model_at_end=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e103aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {'accuracy': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f6e111b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_b/_c0t1fln50qc89tn73q7jhbm0000gn/T/ipykernel_92529/455295994.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb346d",
   "metadata": {},
   "source": [
    "## Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0e20a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=2.0697107950846356, metrics={'train_runtime': 4.498, 'train_samples_per_second': 48.021, 'train_steps_per_second': 3.335, 'total_flos': 7154004934656.0, 'train_loss': 2.0697107950846356, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7bba22",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d33b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0598747730255127, 'eval_accuracy': 0.125, 'eval_runtime': 0.2253, 'eval_samples_per_second': 106.52, 'eval_steps_per_second': 8.877, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa133988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   complaint       0.00      0.00      0.00         3\n",
      "     goodbye       0.00      0.00      0.00         3\n",
      "   gratitude       0.00      0.00      0.00         3\n",
      "    greeting       0.00      0.00      0.00         3\n",
      "        joke       0.00      0.00      0.00         3\n",
      "  restaurant       0.00      0.00      0.00         3\n",
      "      travel       0.14      1.00      0.24         3\n",
      "     weather       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.12        24\n",
      "   macro avg       0.02      0.12      0.03        24\n",
      "weighted avg       0.02      0.12      0.03        24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "preds = trainer.predict(val_ds)\n",
    "y_true = preds.label_ids\n",
    "y_pred = preds.predictions.argmax(axis=-1)\n",
    "print(classification_report(y_true, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7150065f",
   "metadata": {},
   "source": [
    "## Step 8: Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1af67d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "travel\n"
     ]
    }
   ],
   "source": [
    "def classify(text):\n",
    "    # 1. Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
    "    \n",
    "    # 2. Move the input tensors to the same device as the model\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # 3. Perform inference with no gradient calculation for efficiency\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # 4. Get the prediction\n",
    "    pred_id = outputs.logits.argmax(dim=-1).item()\n",
    "    \n",
    "    return id2label[pred_id]\n",
    "\n",
    "print(classify('อากาศดีไหม'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
