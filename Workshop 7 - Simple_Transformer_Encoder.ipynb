{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "193c2b63",
   "metadata": {},
   "source": [
    "# Workshop: Simple Transformer Encoder with Next-Word Prediction\n",
    "This workshop builds a simple Transformer encoder from scratch, trains it on a toy dataset, and predicts the next word given an input sequence.\n",
    "\n",
    "We cover positional encoding, multi-head attention, feed-forward layers, residual connections, and a training loop for next-word prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37918c",
   "metadata": {},
   "source": [
    "## Toy Dataset Preparation\n",
    "We create a small vocabulary and toy sentences for training. Each sentence is tokenized into word indices.\n",
    "Input sequences exclude the last word; target sequences exclude the first word (teacher forcing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d99cdf9",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "Our `SimpleTransformerModel` includes:\n",
    "- Embedding layer to convert word indices into vectors\n",
    "- Positional encoding to add position information\n",
    "- Transformer encoder layer (self-attention + feed-forward)\n",
    "- Linear output layer to predict token scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb803d41",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "We train the model using cross-entropy loss.\n",
    "The optimizer updates the model weights to minimize prediction error over epochs.\n",
    "Batches of sequences are fed into the model, and loss is accumulated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e934b21b",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Given an input sequence of words, the model outputs logits for the next word.\n",
    "We select the word with the highest probability as the predicted next word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b6f65",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We implemented key Transformer components and trained a simple next-word predictor.\n",
    "- This foundational exercise demonstrates how Transformers learn sequence dependencies.\n",
    "- Extend this by increasing dataset size, stacking layers, or adding decoders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c030e40",
   "metadata": {},
   "source": [
    "# Workshop: Build a Simple Transformer Encoder from Scratch\n",
    "This workshop demonstrates the core concepts of the Transformer architecture by implementing a simplified Transformer encoder using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed064abd",
   "metadata": {},
   "source": [
    "## Key Components of Transformer Encoder\n",
    "- Positional Encoding\n",
    "- Multi-Head Self-Attention\n",
    "- Feed-Forward Neural Network\n",
    "- Layer Normalization and Residual Connections\n",
    "\n",
    "This implementation focuses on the encoder part only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022acac",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d295b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616c994",
   "metadata": {},
   "source": [
    "## Step 2: Positional Encoding\n",
    "Positional Encoding injects information about the token position into embeddings since Transformer has no recurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "804da413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)  # Shape: (max_len, 1, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_len, batch_size, d_model)\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6723a840",
   "metadata": {},
   "source": [
    "## Step 3: Multi-Head Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955d1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.linear_q = nn.Linear(d_model, d_model)\n",
    "        self.linear_k = nn.Linear(d_model, d_model)\n",
    "        self.linear_v = nn.Linear(d_model, d_model)\n",
    "        self.linear_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def attention(self, query, key, value, mask=None):\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        p_attn = torch.softmax(scores, dim=-1)\n",
    "        p_attn = self.dropout(p_attn)\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(1)\n",
    "\n",
    "        # Linear projections\n",
    "        query = self.linear_q(query).view(-1, batch_size, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        key = self.linear_k(key).view(-1, batch_size, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        value = self.linear_v(value).view(-1, batch_size, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Apply attention\n",
    "        x, attn = self.attention(query, key, value, mask=mask)\n",
    "\n",
    "        # Concat heads\n",
    "        x = x.transpose(1, 2).contiguous().view(-1, batch_size, self.d_model)\n",
    "\n",
    "        # Final linear layer\n",
    "        return self.linear_out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea81cb",
   "metadata": {},
   "source": [
    "## Step 4: Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a71cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3963815",
   "metadata": {},
   "source": [
    "## Step 5: Transformer Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c27bfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        # Self-attention + add & norm\n",
    "        src2 = self.self_attn(src, src, src, mask=src_mask)\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "\n",
    "        # Feed-forward + add & norm\n",
    "        src2 = self.feed_forward(src)\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779283ba",
   "metadata": {},
   "source": [
    "## Step 6: Instantiate and Run Encoder on Sample Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7397145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([10, 2, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "seq_len = 10\n",
    "batch_size = 2\n",
    "\n",
    "encoder_layer = TransformerEncoderLayer(d_model, num_heads).to(device)\n",
    "pos_encoder = PositionalEncoding(d_model).to(device)\n",
    "\n",
    "# Random input embeddings (seq_len, batch_size, d_model)\n",
    "input_embeddings = torch.rand(seq_len, batch_size, d_model).to(device)\n",
    "\n",
    "# Add positional encoding\n",
    "input_pos_encoded = pos_encoder(input_embeddings)\n",
    "\n",
    "# Forward pass through encoder\n",
    "output = encoder_layer(input_pos_encoded)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d83647-a5da-425b-a596-29ffd3646865",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "       Encoded Output\n",
    "             ^\n",
    "             |\n",
    "        Add & Norm 2\n",
    "          ^     ^\n",
    "          |     | (Residual)\n",
    "          |     |\n",
    "Feed-Forward Network\n",
    "          ^\n",
    "          |\n",
    "       Add & Norm 1\n",
    "          ^     ^\n",
    "          |     | (Residual)\n",
    "          |     |\n",
    "Multi-Head Self-Attention\n",
    "          ^\n",
    "          |\n",
    "Positional Encoding\n",
    "          ^\n",
    "          |\n",
    "  Input Embeddings\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e26f93",
   "metadata": {},
   "source": [
    "## Step 7: Train Transformer for Next-Word Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4980328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 0, 'love': 1, 'machine': 2, 'learning': 3, 'and': 4, 'deep': 5, 'neural': 6, 'networks': 7, '<pad>': 8}\n",
      "{0: 'i', 1: 'love', 2: 'machine', 3: 'learning', 4: 'and', 5: 'deep', 6: 'neural', 7: 'networks', 8: '<pad>'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Toy dataset: simple tokenized sentences (word indices)\n",
    "vocab = ['i', 'love', 'machine', 'learning', 'and', 'deep', 'neural', 'networks', '<pad>']\n",
    "word2idx = {w: idx for idx, w in enumerate(vocab)}\n",
    "print(word2idx)\n",
    "\n",
    "idx2word = {idx: w for w, idx in word2idx.items()}\n",
    "print(idx2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b048411-8a05-4126-950e-7b6347916726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2], [2, 3, 4], [5, 6, 7], [0, 1, 5], [6, 7, 4]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\n",
    "    ['i', 'love', 'machine'],\n",
    "    ['machine', 'learning', 'and'],\n",
    "    ['deep', 'neural', 'networks'],\n",
    "    ['i', 'love', 'deep'],\n",
    "    ['neural', 'networks', 'and'],\n",
    "]\n",
    "\n",
    "max_len = 3\n",
    "\n",
    "# Convert to indices\n",
    "def encode(sent):\n",
    "    return [word2idx[w] for w in sent]\n",
    "\n",
    "encoded_sents = [encode(sent) for sent in sentences]\n",
    "print(encoded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d0719a-8643-41f7-8bb4-786972e3c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.1375\n",
      "Epoch 20, Loss: 0.1704\n",
      "Epoch 30, Loss: 0.1275\n",
      "Epoch 40, Loss: 0.1327\n",
      "Epoch 50, Loss: 0.1151\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx][:-1])\n",
    "        y = torch.tensor(self.data[idx][1:])\n",
    "        return x, y\n",
    "\n",
    "dataset = ToyDataset(encoded_sents)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Extend TransformerEncoderLayer to include Embedding and output layer\n",
    "class SimpleTransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, d_ff=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model, num_heads, d_ff)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # src shape: (seq_len, batch_size)\n",
    "        embedded = self.embedding(src)  # (seq_len, batch_size, d_model)\n",
    "        pos_encoded = self.pos_encoder(embedded)\n",
    "        encoded = self.encoder_layer(pos_encoded)\n",
    "        output = self.fc_out(encoded)\n",
    "        return output\n",
    "\n",
    "# Initialize model\n",
    "vocab_size = len(vocab)\n",
    "model = SimpleTransformerModel(vocab_size, d_model=32, num_heads=4, d_ff=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        x_batch = x_batch.transpose(0,1).to(device)  # (seq_len, batch)\n",
    "        y_batch = y_batch.transpose(0,1).to(device)  # (seq_len, batch)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)  # (seq_len, batch, vocab_size)\n",
    "        loss = criterion(output.view(-1, vocab_size), y_batch.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Prediction: Given an input sequence, predict next word\n",
    "def predict_next_word(model, input_words):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = torch.tensor([word2idx[w] for w in input_words]).unsqueeze(1).to(device)  # (seq_len, batch=1)\n",
    "        output = model(input_ids)  # (seq_len, batch, vocab_size)\n",
    "        last_token_logits = output[-1, 0]\n",
    "        predicted_idx = torch.argmax(last_token_logits).item()\n",
    "        return idx2word[predicted_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38190961-36f4-4eff-baa0-f5c068d4588d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given input words ['i', 'love'], predicted next word: machine\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_sequence = ['i', 'love']\n",
    "predicted_word = predict_next_word(model, input_sequence)\n",
    "print(f\"Given input words {input_sequence}, predicted next word: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6023b9c-8af7-4a96-b95f-11b7e83698d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given input words ['i', 'love', 'machine'], predicted next word: learning\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_sequence = ['i', 'love', 'machine']\n",
    "predicted_word = predict_next_word(model, input_sequence)\n",
    "print(f\"Given input words {input_sequence}, predicted next word: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2570d1-629e-4f80-a858-2e17905ac757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev-ai]",
   "language": "python",
   "name": "conda-env-dev-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
